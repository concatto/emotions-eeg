{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read file and fix classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from helpers import EstimatorSelectionHelper\n",
    "\n",
    "win_overlaps = [(800, 400), (800, 0), (400, 200), (400, 0), (200, 100), (200, 0)]\n",
    "\n",
    "def read_features_file(folder, win_size, overlap_size):\n",
    "    df_features = pd.read_pickle(f\"{folder}\\\\features_win_size_{win_size}_overlap_size_{overlap_size}.pkl\")    \n",
    "    df_features.loc[df_features['label'] == 0, 'label'] = 0\n",
    "    df_features.loc[df_features['label'] == 1, 'label'] = 1\n",
    "    df_features.loc[df_features['label'] == 3, 'label'] = 2\n",
    "    return df_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features = read_features_file('D:\\\\facul\\\\features', 400, 200)\n",
    "\n",
    "df_features.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set models and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, Normalizer, PowerTransformer, MinMaxScaler\n",
    "from sklearn.feature_selection import f_classif, SelectKBest, chi2, mutual_info_classif\n",
    "from sklearn.decomposition import PCA\n",
    "from helpers import EstimatorSelectionHelper\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis \n",
    "from datetime import datetime\n",
    "import pickle\n",
    "\n",
    "models = {\n",
    "    'LinearDiscriminantAnalysis': LinearDiscriminantAnalysis(),\n",
    "    'RandomForestClassifier': RandomForestClassifier(),\n",
    "    'LogisticRegression': Pipeline([\n",
    "        ('scaling', StandardScaler()),\n",
    "        ('estimator', LogisticRegression()),\n",
    "\n",
    "    ]),\n",
    "    'MLPClassifier': Pipeline([\n",
    "        ('scaling', StandardScaler()),\n",
    "        ('estimator', MLPClassifier(solver='lbfgs')),\n",
    "\n",
    "    ]),\n",
    "    'LinearSVC': Pipeline([\n",
    "        ('scaling', StandardScaler()),\n",
    "        ('estimator', LinearSVC())\n",
    "    ]),\n",
    "    'SVC': Pipeline([\n",
    "        # ('feat', SelectKBest(mutual_info_classif, k=20)),        \n",
    "        ('scaling', StandardScaler()),\n",
    "        ('estimator', SVC())\n",
    "    ])\n",
    "}\n",
    "\n",
    "params = {\n",
    "    'LinearDiscriminantAnalysis': {},\n",
    "    'RandomForestClassifier': { 'n_estimators': [16, 32, 48, 100] },\n",
    "    'LogisticRegression': {'estimator__C': [0.01, 0.03, 0.1, 0.3, 1, 3]},\n",
    "    'MLPClassifier': {\n",
    "        'estimator__hidden_layer_sizes': [(15,10), (10,5), (5,3),(30,15,10), (20,15,10), (15,10,5)],\n",
    "        'estimator__alpha': np.logspace(-1, -7, num=7)\n",
    "    },\n",
    "    'LinearSVC': [\n",
    "        {'estimator__C': np.logspace(5, -5, base=2, num=10)},\n",
    "    ],\n",
    "    'SVC': [\n",
    "        {'estimator__C': np.logspace(15, -15, base=2, num=31), 'estimator__gamma': np.logspace(8, -8, base=10, num=17)},\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1: Subject-dependent models with sessions randomly mixed between different days "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "5\n",
      "dict_keys(['LinearDiscriminantAnalysis', 'RandomForestClassifier'])\n",
      "Running GridSearchCV for LinearDiscriminantAnalysis with nested cross validation.\n",
      "[CV]  ................................................................\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    6.3s remaining:    9.5s\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:    6.3s remaining:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    6.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    6.5s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    6.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[CV] ................ , score=(train=0.395, test=0.261), total=   6.7s\n",
      "[CV]  ................................................................\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.3s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:    0.3s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    7.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[CV] ................ , score=(train=0.432, test=0.361), total=   0.5s\n",
      "[CV]  ................................................................\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1107s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    7.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[CV] ................ , score=(train=0.395, test=0.339), total=   0.2s\n",
      "[CV]  ................................................................\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0758s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    7.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[CV] ................ , score=(train=0.375, test=0.352), total=   0.2s\n",
      "[CV]  ................................................................\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1217s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    7.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    7.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[CV] ................ , score=(train=0.383, test=0.304), total=   0.3s\n",
      "Object persisted\n",
      "Running GridSearchCV for RandomForestClassifier with nested cross validation.\n",
      "[CV]  ................................................................\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  20 | elapsed:    7.3s remaining:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    9.7s finished\n",
      "[CV] ................ , score=(train=1.000, test=0.382), total=  11.3s\n",
      "[CV]  ................................................................\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   11.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done   6 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done   7 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done  11 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    0.9s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Kevin\\Desktop\\facul\\tcc-code\\experiments\\kaggle-emotion-detector\\helpers.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, cv, n_jobs, verbose, scoring, refit, groups, outer_cv, persist_dir, randomSearchFor)\u001b[0m\n\u001b[0;32m    235\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Running GridSearchCV for %s with nested cross validation.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m                 self.cross_val_results[key] = cross_validate(gs, X, y, groups=groups, cv=outer_cv, scoring=scoring, error_score='raise',\n\u001b[1;32m--> 237\u001b[1;33m                                                              return_train_score=True, return_estimator=True, verbose=10, fit_params={'groups': groups})\n\u001b[0m\u001b[0;32m    238\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mran_with_outer_cv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m                 gs = max(\n",
      "\u001b[1;32mD:\\programs\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    234\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m             error_score=error_score)\n\u001b[1;32m--> 236\u001b[1;33m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[0;32m    237\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\programs\\anaconda\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1005\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1007\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1008\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1009\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\programs\\anaconda\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    833\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    834\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 835\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    836\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\programs\\anaconda\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    752\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 754\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    755\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\programs\\anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    207\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\programs\\anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    588\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    589\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 590\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    591\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\programs\\anaconda\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 256\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\programs\\anaconda\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 256\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\programs\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    513\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    514\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 515\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    516\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    517\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\programs\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    708\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 710\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    711\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    712\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\programs\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1149\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1150\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1151\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\programs\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    687\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m                                in product(candidate_params,\n\u001b[1;32m--> 689\u001b[1;33m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    690\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    691\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\programs\\anaconda\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1015\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1017\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1018\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1019\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\programs\\anaconda\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    907\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    908\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 909\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    910\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    911\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\programs\\anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    560\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    561\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 562\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    563\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    564\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\programs\\anaconda\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    425\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 427\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    428\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\programs\\anaconda\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    293\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%load_ext autoreload\n",
    "%autoreload \n",
    "from helpers import RepeatedStratifiedGroupKFold\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, Normalizer, PowerTransformer, MinMaxScaler\n",
    "from sklearn.feature_selection import f_classif, SelectKBest, chi2, mutual_info_classif\n",
    "from sklearn.decomposition import PCA\n",
    "from helpers import EstimatorSelectionHelper\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis \n",
    "from datetime import datetime\n",
    "import pickle\n",
    "\n",
    "cols = ['session', 'trial', 'user', 'label', 'T7', 'T8', 'FT7', 'FT8', 'TP7', 'TP8']\n",
    "\n",
    "\n",
    "# df_features_cols = df_features.loc[df_features['session'] == 1, df_features.filter(regex=r\"({})\".format('|'.join(cols)), axis=1).columns]\n",
    "df_features_cols = df_features.loc[:, df_features.filter(regex=r\"({})\".format('|'.join(cols)), axis=1).columns]\n",
    "\n",
    "\n",
    "df_user_scores = pd.DataFrame()\n",
    "\n",
    "user_helper_list = []\n",
    "\n",
    "folder = './models/user-dependent-mixed-days'\n",
    "\n",
    "for user in range(1, 16):\n",
    "\n",
    "    cv_grp = RepeatedStratifiedGroupKFold(n_splits=5, n_repeats=1)\n",
    "    outer_cv_grp = RepeatedStratifiedGroupKFold(n_splits=5, n_repeats=1)\n",
    "\n",
    "    print(outer_cv_grp.get_n_splits())\n",
    "\n",
    "    helper = EstimatorSelectionHelper(models, params)\n",
    "    user_helper_list.append(helper)\n",
    "\n",
    "    X = df_features_cols.loc[df_features_cols['user'].isin([user]), ~df_features_cols.columns.isin(['session', 'trial', 'user', 'label'])]\n",
    "    y = df_features_cols.loc[df_features_cols['user'].isin([user]), 'label'].astype(int)\n",
    "\n",
    "\n",
    "    groups = df_features_cols.loc[df_features_cols['user'].isin([user]), 'trial']\n",
    "\n",
    "    # helper.fit(X, y, scoring='f1', n_jobs=2, cv=cv_grp, outer_cv=outer_cv_grp, groups=df_features_cols['trial'])\n",
    "    helper.fit(X, y, scoring='accuracy', n_jobs=-1, cv=cv_grp, outer_cv=outer_cv_grp, verbose=10, groups=groups, persist_dir=f\"{folder}/user_{user}_{datetime.now().strftime('%Y-%m-%dT%H-%M-%S.pkl')}\", randomSearchFor=['MLPClassifier', 'SVC'])\n",
    "\n",
    "    temp_scores = helper.score_summary(sort_by='mean_score')\n",
    "    temp_scores.insert(0, 'user', user)\n",
    "    df_user_scores = df_user_scores.append(temp_scores)\n",
    "\n",
    "with open(f\"{folder}/all_users_{datetime.now().strftime('%Y-%m-%dT%H-%M-%S.pkl')}\", \"wb\") as f:\n",
    "    pickle.dump(user_helper_list, f)\n",
    "\n",
    "df_user_scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2: Subject-dependent models with sessions within the same days\n",
    "#### - 1 trained per day/user/model-type \n",
    "#### - Need to calculate the average of the model performance between the 3 days "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ng:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[CV] ................ , score=(train=0.819, test=0.782), total=   0.1s\n",
      "Object persisted\n",
      "Running GridSearchCV for RandomForestClassifier with nested cross validation.\n",
      "[CV]  ................................................................\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0728s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.3s remaining:    0.0s\n",
      "[CV] ................ , score=(train=1.000, test=0.820), total=   1.4s\n",
      "[CV]  ................................................................\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0758s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  20 | elapsed:    0.7s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    2.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0758s.) Setting batch_size=2.\n",
      "[CV] ................ , score=(train=1.000, test=0.838), total=   1.2s\n",
      "[CV]  ................................................................\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  20 | elapsed:    0.7s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    1.1s finished\n",
      "[CV] ................ , score=(train=1.000, test=0.824), total=   1.6s\n",
      "[CV]  ................................................................\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    4.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0852s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  20 | elapsed:    0.8s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    5.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[CV] ................ , score=(train=1.000, test=0.699), total=   1.4s\n",
      "[CV]  ................................................................\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0798s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    7.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    7.0s finished\n",
      "[CV] ................ , score=(train=1.000, test=0.809), total=   1.3s\n",
      "Object persisted\n",
      "Running GridSearchCV for LogisticRegression with nested cross validation.\n",
      "[CV]  ................................................................\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0359s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1267s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  23 out of  30 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  30 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    0.3s finished\n",
      "[CV] ................ , score=(train=0.900, test=0.809), total=   0.6s\n",
      "[CV]  ................................................................\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0299s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1177s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  23 out of  30 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  30 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    0.4s finished\n",
      "[CV] ................ , score=(train=0.874, test=0.925), total=   0.7s\n",
      "[CV]  ................................................................\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    1.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0379s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1127s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  30 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    0.3s finished\n",
      "[CV] ................ , score=(train=0.903, test=0.590), total=   0.6s\n",
      "[CV]  ................................................................\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0309s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1187s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  23 out of  30 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  30 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    0.4s finished\n",
      "[CV] ................ , score=(train=0.933, test=0.593), total=   0.8s\n",
      "[CV]  ................................................................\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    2.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0369s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1117s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  23 out of  30 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  30 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    3.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    3.3s finished\n",
      "[CV] ................ , score=(train=0.885, test=0.805), total=   0.6s\n",
      "Object persisted\n",
      "Running GridSearchCV for MLPClassifier with nested cross validation.\n",
      "[CV]  ................................................................\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1356s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    3.2s finished\n",
      "[CV] ................ , score=(train=1.000, test=0.794), total=   4.0s\n",
      "[CV]  ................................................................\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    4.3s finished\n",
      "[CV] ................ , score=(train=1.000, test=0.891), total=   5.4s\n",
      "[CV]  ................................................................\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    9.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1695s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done  43 out of  50 | elapsed:    3.2s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    3.3s finished\n",
      "[CV] ................ , score=(train=0.997, test=0.674), total=   4.9s\n",
      "[CV]  ................................................................\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   14.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    4.0s finished\n",
      "[CV] ................ , score=(train=0.989, test=0.555), total=   5.2s\n",
      "[CV]  ................................................................\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   19.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1277s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done  43 out of  50 | elapsed:    3.5s remaining:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    3.7s finished\n",
      "[CV] ................ , score=(train=0.989, test=0.743), total=   4.9s\n",
      "Object persisted\n",
      "Running GridSearchCV for LinearSVC with nested cross validation.\n",
      "[CV]  ................................................................\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   24.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   24.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0918s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[CV] ................ , score=(train=0.883, test=0.772), total=   1.4s\n",
      "[CV]  ................................................................\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1316s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.2s remaining:    0.0s\n",
      "[CV] ................ , score=(train=0.858, test=0.910), total=   1.8s\n",
      "[CV]  ................................................................\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1297s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    1.4s finished\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    4.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[CV] ................ , score=(train=0.908, test=0.617), total=   1.7s\n",
      "[CV]  ................................................................\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1386s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    1.3s finished\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    6.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[CV] ................ , score=(train=0.931, test=0.555), total=   1.6s\n",
      "[CV]  ................................................................\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1287s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    8.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    8.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[CV] ................ , score=(train=0.881, test=0.852), total=   1.7s\n",
      "Object persisted\n",
      "Running GridSearchCV for SVC with nested cross validation.\n",
      "[CV]  ................................................................\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1686s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0848s.) Setting batch_size=2.\n",
      "[CV] ................ , score=(train=0.990, test=0.811), total=   1.8s\n",
      "[CV]  ................................................................\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    1.3s finished\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[CV] ................ , score=(train=0.918, test=0.669), total=   1.5s\n",
      "[CV]  ................................................................\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    5.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[CV] ................ , score=(train=0.935, test=0.759), total=   2.2s\n",
      "[CV]  ................................................................\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1107s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    1.8s finished\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    7.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0658s.) Setting batch_size=2.\n",
      "[CV] ................ , score=(train=0.866, test=0.574), total=   2.0s\n",
      "[CV]  ................................................................\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    9.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    9.3s finished\n",
      "[CV] ................ , score=(train=0.826, test=0.739), total=   1.8s\n",
      "Object persisted\n",
      "Wall time: 53min 8s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>user</th>\n",
       "      <th>estimator</th>\n",
       "      <th>min_score</th>\n",
       "      <th>max_score</th>\n",
       "      <th>mean_score</th>\n",
       "      <th>std_score</th>\n",
       "      <th>train_mean_score</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>estimator__C</th>\n",
       "      <th>estimator__alpha</th>\n",
       "      <th>estimator__hidden_layer_sizes</th>\n",
       "      <th>estimator__gamma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>0.277512</td>\n",
       "      <td>0.511111</td>\n",
       "      <td>0.382965</td>\n",
       "      <td>0.083175</td>\n",
       "      <td>0.512056</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.367698</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>0.413429</td>\n",
       "      <td>0.043020</td>\n",
       "      <td>0.998772</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.420635</td>\n",
       "      <td>0.366543</td>\n",
       "      <td>0.036591</td>\n",
       "      <td>0.470970</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.311005</td>\n",
       "      <td>0.460317</td>\n",
       "      <td>0.378056</td>\n",
       "      <td>0.057923</td>\n",
       "      <td>0.660978</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001</td>\n",
       "      <td>(10, 5)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.287081</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.389457</td>\n",
       "      <td>0.053441</td>\n",
       "      <td>0.494454</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.698864</td>\n",
       "      <td>0.838346</td>\n",
       "      <td>0.798162</td>\n",
       "      <td>0.050510</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.590308</td>\n",
       "      <td>0.924812</td>\n",
       "      <td>0.744512</td>\n",
       "      <td>0.131901</td>\n",
       "      <td>0.898900</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.555024</td>\n",
       "      <td>0.890977</td>\n",
       "      <td>0.731323</td>\n",
       "      <td>0.113036</td>\n",
       "      <td>0.995100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(20, 15, 10)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.555024</td>\n",
       "      <td>0.909774</td>\n",
       "      <td>0.741159</td>\n",
       "      <td>0.135552</td>\n",
       "      <td>0.892107</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.573864</td>\n",
       "      <td>0.810726</td>\n",
       "      <td>0.710464</td>\n",
       "      <td>0.082012</td>\n",
       "      <td>0.906919</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1e-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>270 rows  13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    day  user                   estimator  min_score  max_score  mean_score  \\\n",
       "0     1     1  LinearDiscriminantAnalysis   0.277512   0.511111    0.382965   \n",
       "0     1     1      RandomForestClassifier   0.367698   0.472222    0.413429   \n",
       "0     1     1          LogisticRegression   0.315789   0.420635    0.366543   \n",
       "0     1     1               MLPClassifier   0.311005   0.460317    0.378056   \n",
       "0     1     1                   LinearSVC   0.287081   0.444444    0.389457   \n",
       "..  ...   ...                         ...        ...        ...         ...   \n",
       "0     3    15      RandomForestClassifier   0.698864   0.838346    0.798162   \n",
       "0     3    15          LogisticRegression   0.590308   0.924812    0.744512   \n",
       "0     3    15               MLPClassifier   0.555024   0.890977    0.731323   \n",
       "0     3    15                   LinearSVC   0.555024   0.909774    0.741159   \n",
       "0     3    15                         SVC   0.573864   0.810726    0.710464   \n",
       "\n",
       "    std_score  train_mean_score n_estimators estimator__C estimator__alpha  \\\n",
       "0    0.083175          0.512056          NaN          NaN              NaN   \n",
       "0    0.043020          0.998772           16          NaN              NaN   \n",
       "0    0.036591          0.470970          NaN         0.01              NaN   \n",
       "0    0.057923          0.660978          NaN          NaN            0.001   \n",
       "0    0.053441          0.494454          NaN         32.0              NaN   \n",
       "..        ...               ...          ...          ...              ...   \n",
       "0    0.050510          1.000000           16          NaN              NaN   \n",
       "0    0.131901          0.898900          NaN         0.01              NaN   \n",
       "0    0.113036          0.995100          NaN          NaN              0.1   \n",
       "0    0.135552          0.892107          NaN         32.0              NaN   \n",
       "0    0.082012          0.906919          NaN         0.25              NaN   \n",
       "\n",
       "   estimator__hidden_layer_sizes estimator__gamma  \n",
       "0                            NaN              NaN  \n",
       "0                            NaN              NaN  \n",
       "0                            NaN              NaN  \n",
       "0                        (10, 5)              NaN  \n",
       "0                            NaN              NaN  \n",
       "..                           ...              ...  \n",
       "0                            NaN              NaN  \n",
       "0                            NaN              NaN  \n",
       "0                   (20, 15, 10)              NaN  \n",
       "0                            NaN              NaN  \n",
       "0                            NaN            1e-05  \n",
       "\n",
       "[270 rows x 13 columns]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "%load_ext autoreload\n",
    "%autoreload \n",
    "from helpers import RepeatedStratifiedGroupKFold\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, Normalizer, PowerTransformer, MinMaxScaler\n",
    "from sklearn.feature_selection import f_classif, SelectKBest, chi2, mutual_info_classif\n",
    "from sklearn.decomposition import PCA\n",
    "from helpers import EstimatorSelectionHelper\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis \n",
    "from datetime import datetime\n",
    "import pickle\n",
    "\n",
    "cols = ['session', 'trial', 'user', 'label', 'T7', 'T8', 'FT7', 'FT8', 'TP7', 'TP8']\n",
    "\n",
    "df_features = read_features_file('D:\\\\facul\\\\features', 800, 400)\n",
    "\n",
    "df_features_cols = df_features.loc[:, df_features.filter(regex=r\"({})\".format('|'.join(cols)), axis=1).columns]\n",
    "\n",
    "\n",
    "df_user_scores = pd.DataFrame()\n",
    "\n",
    "folder = './models/user-dependent-same-days'\n",
    "\n",
    "for day in range(1, 4):\n",
    "    user_helper_list = []\n",
    "\n",
    "    for user in range(1, 16):\n",
    "\n",
    "        cv_grp = RepeatedStratifiedGroupKFold(n_splits=5, n_repeats=1)\n",
    "        outer_cv_grp = RepeatedStratifiedGroupKFold(n_splits=5, n_repeats=1)\n",
    "\n",
    "        print(outer_cv_grp.get_n_splits())\n",
    "\n",
    "        helper = EstimatorSelectionHelper(models, params)\n",
    "        user_helper_list.append(helper)\n",
    "\n",
    "        user_day_index = (df_features_cols['user'].isin([user])) & (df_features_cols['session'] == day)\n",
    "\n",
    "        X = df_features_cols.loc[user_day_index, ~df_features_cols.columns.isin(['session', 'trial', 'user', 'label'])]\n",
    "        \n",
    "        y = df_features_cols.loc[user_day_index, 'label'].astype(int)\n",
    "\n",
    "        groups = df_features_cols.loc[user_day_index, 'trial']\n",
    "\n",
    "        # helper.fit(X, y, scoring='f1', n_jobs=2, cv=cv_grp, outer_cv=outer_cv_grp, groups=df_features_cols['trial'])\n",
    "        helper.fit(X, y, scoring='accuracy', n_jobs=-1, cv=cv_grp, outer_cv=outer_cv_grp, verbose=10, groups=groups, persist_dir=f\"{folder}/user_{user}_day_{day}_{datetime.now().strftime('%Y-%m-%dT%H-%M-%S.pkl')}\", randomSearchFor=['MLPClassifier', 'SVC'])\n",
    "\n",
    "        temp_scores = helper.score_summary(sort_by='mean_score')\n",
    "        temp_scores.insert(0, 'user', user)\n",
    "        temp_scores.insert(0, 'day', day)\n",
    "        df_user_scores = df_user_scores.append(temp_scores)\n",
    "\n",
    "    with open(f\"{folder}/all_users_day_{day}_{datetime.now().strftime('%Y-%m-%dT%H-%M-%S.pkl')}\", \"wb\") as f:\n",
    "        pickle.dump(user_helper_list, f)\n",
    "\n",
    "df_user_scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The first implementation was generated with accumulated results (it was a bug), but given the time constraints, we did not regenerate the data, but we fixed the bug. This means that all the data is accumulated on the day 3 file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<helpers.EstimatorSelectionHelper at 0x238b56cbc18>,\n",
       " <helpers.EstimatorSelectionHelper at 0x238b965a2e8>,\n",
       " <helpers.EstimatorSelectionHelper at 0x238ba790c50>,\n",
       " <helpers.EstimatorSelectionHelper at 0x238bb870940>,\n",
       " <helpers.EstimatorSelectionHelper at 0x238bc9b3160>,\n",
       " <helpers.EstimatorSelectionHelper at 0x238bdc221d0>,\n",
       " <helpers.EstimatorSelectionHelper at 0x238bed5b9b0>,\n",
       " <helpers.EstimatorSelectionHelper at 0x238bfef6fd0>,\n",
       " <helpers.EstimatorSelectionHelper at 0x238bca88d30>,\n",
       " <helpers.EstimatorSelectionHelper at 0x238c32d3898>,\n",
       " <helpers.EstimatorSelectionHelper at 0x238c4400630>,\n",
       " <helpers.EstimatorSelectionHelper at 0x238c54eda58>,\n",
       " <helpers.EstimatorSelectionHelper at 0x238c6635278>,\n",
       " <helpers.EstimatorSelectionHelper at 0x238c7785a58>,\n",
       " <helpers.EstimatorSelectionHelper at 0x238c88863c8>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_users_data = EstimatorSelectionHelper.load(\"./models/user-dependent-same-days/all_users_day_3_2020-06-20T18-06-38.pkl\")\n",
    "# data_days = [\n",
    "all_users_data[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get models with best scores for each user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user</th>\n",
       "      <th>estimator</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.484388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2.0</th>\n",
       "      <th>LinearDiscriminantAnalysis</th>\n",
       "      <td>0.713086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.629984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.651907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">3.0</th>\n",
       "      <th>LinearDiscriminantAnalysis</th>\n",
       "      <td>0.487387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.509086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">4.0</th>\n",
       "      <th>LinearSVC</th>\n",
       "      <td>0.614193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.738750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">5.0</th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.575294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.585441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">6.0</th>\n",
       "      <th>LinearSVC</th>\n",
       "      <td>0.776448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.534637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.816302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">7.0</th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.701405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.671499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.509074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">8.0</th>\n",
       "      <th>LinearDiscriminantAnalysis</th>\n",
       "      <td>0.621244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVC</th>\n",
       "      <td>0.499767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.765832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">9.0</th>\n",
       "      <th>LinearDiscriminantAnalysis</th>\n",
       "      <td>0.517008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVC</th>\n",
       "      <td>0.576516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPClassifier</th>\n",
       "      <td>0.612489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">10.0</th>\n",
       "      <th>LinearDiscriminantAnalysis</th>\n",
       "      <td>0.554244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.674094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">11.0</th>\n",
       "      <th>LinearDiscriminantAnalysis</th>\n",
       "      <td>0.441824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVC</th>\n",
       "      <td>0.548680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">12.0</th>\n",
       "      <th>LinearDiscriminantAnalysis</th>\n",
       "      <td>0.428662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVC</th>\n",
       "      <td>0.486102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.501490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">13.0</th>\n",
       "      <th>LinearDiscriminantAnalysis</th>\n",
       "      <td>0.701781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.453562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">14.0</th>\n",
       "      <th>LinearSVC</th>\n",
       "      <td>0.524749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.500520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.701340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">15.0</th>\n",
       "      <th>LinearSVC</th>\n",
       "      <td>0.730137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.834332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 mean_score\n",
       "user estimator                             \n",
       "1.0  RandomForestClassifier        0.484388\n",
       "2.0  LinearDiscriminantAnalysis    0.713086\n",
       "     LogisticRegression            0.629984\n",
       "     RandomForestClassifier        0.651907\n",
       "3.0  LinearDiscriminantAnalysis    0.487387\n",
       "     RandomForestClassifier        0.509086\n",
       "4.0  LinearSVC                     0.614193\n",
       "     RandomForestClassifier        0.738750\n",
       "5.0  LogisticRegression            0.575294\n",
       "     RandomForestClassifier        0.585441\n",
       "6.0  LinearSVC                     0.776448\n",
       "     RandomForestClassifier        0.534637\n",
       "     SVC                           0.816302\n",
       "7.0  LogisticRegression            0.701405\n",
       "     RandomForestClassifier        0.671499\n",
       "     SVC                           0.509074\n",
       "8.0  LinearDiscriminantAnalysis    0.621244\n",
       "     LinearSVC                     0.499767\n",
       "     LogisticRegression            0.765832\n",
       "9.0  LinearDiscriminantAnalysis    0.517008\n",
       "     LinearSVC                     0.576516\n",
       "     MLPClassifier                 0.612489\n",
       "10.0 LinearDiscriminantAnalysis    0.554244\n",
       "     RandomForestClassifier        0.674094\n",
       "11.0 LinearDiscriminantAnalysis    0.441824\n",
       "     LinearSVC                     0.548680\n",
       "12.0 LinearDiscriminantAnalysis    0.428662\n",
       "     LinearSVC                     0.486102\n",
       "     RandomForestClassifier        0.501490\n",
       "13.0 LinearDiscriminantAnalysis    0.701781\n",
       "     RandomForestClassifier        0.453562\n",
       "14.0 LinearSVC                     0.524749\n",
       "     LogisticRegression            0.500520\n",
       "     RandomForestClassifier        0.701340\n",
       "15.0 LinearSVC                     0.730137\n",
       "     RandomForestClassifier        0.834332"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_days = [ all_users_data[:15], all_users_data[15:30], all_users_data[30:]]\n",
    "\n",
    "df_results = pd.DataFrame()\n",
    "for data_day in data_days:\n",
    "    for user, user_data in enumerate(data_day):\n",
    "        score_summary = data_day[user].score_summary()\n",
    "        best_score = score_summary.loc[score_summary['mean_score'] == score_summary['mean_score'].max()]\n",
    "\n",
    "        df_results = df_results.append({'user': user+1, 'estimator': best_score.loc[0, 'estimator'], 'mean_score': best_score.loc[0, 'mean_score'] }, ignore_index=True)\n",
    "\n",
    "df_results.groupby(['user', 'estimator'])[['mean_score']].max()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the mean score for the best models for all users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mean_score    0.58898\n",
       "dtype: float64"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.groupby(['user'])[['mean_score']].mean().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a table with all the models (best ones) for each user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_days = [all_users_data[:15], all_users_data[15:30], all_users_data[30:]]\n",
    "data_days[0][0].score_summary()[['estimator', 'mean_score']]\n",
    "\n",
    "df_users_scores = pd.DataFrame(columns=['user'] + list(models.keys()))\n",
    "for day, data_day in enumerate(data_days):\n",
    "    for user, user_data in enumerate(data_day):\n",
    "        score_summary = data_day[user].score_summary()[['estimator', 'mean_score']].set_index('estimator').T\n",
    "        score_summary.insert(0, column='user', value=int(user) + 1)\n",
    "        score_summary.insert(1, column='day', value=int(day))\n",
    "        # score_summary.drop(columns=['estimator'], inplace=True, axis=1)\n",
    "\n",
    "        df_users_scores = df_users_scores.append(score_summary)\n",
    "        # break\n",
    "\n",
    "# df_users_scores.rename_axis(index='None', axis=1, inplace=True)\n",
    "# df_users_scores.index.name = None\n",
    "# df_users_scores.reset_index(drop=False, inplace=True)\n",
    "\n",
    "df_users_scores.columns.name = None\n",
    "df_users_scores.reset_index(drop=True, inplace=True)\n",
    "# df_user_scores.rename({})\n",
    "df_users_scores = df_users_scores.drop(columns=['day']).groupby(['user']).mean().round(4)*100\n",
    "df_for_excel = df_users_scores.reset_index().drop(columns=['LinearSVC','SVC'])\n",
    "\n",
    "df_for_excel =df_for_excel.rename(columns={\n",
    "    'user':                         'Usurio',\n",
    "    'LinearDiscriminantAnalysis':   'LDA',\n",
    "    'RandomForestClassifier':       'Random Forest',\n",
    "    'LogisticRegression':           'Regresso Logstica',\n",
    "    'MLPClassifier':                'Rede Neural (MLP)',\n",
    "})\n",
    "\n",
    "df_for_excel['SVM'] = df_users_scores[['LinearSVC','SVC']].max(axis=1)\n",
    "\n",
    "df_for_excel.to_excel('user-dependent-same-days.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0.399592\n",
       "1     0.694628\n",
       "2     0.393085\n",
       "3     0.614193\n",
       "4     0.448867\n",
       "5     0.454028\n",
       "6     0.663884\n",
       "7     0.499767\n",
       "8     0.576516\n",
       "9     0.479004\n",
       "10    0.438735\n",
       "11    0.486102\n",
       "12    0.507980\n",
       "13    0.524749\n",
       "14    0.730137\n",
       "15    0.448810\n",
       "16    0.604981\n",
       "17    0.460137\n",
       "18    0.636266\n",
       "19    0.571678\n",
       "20    0.776448\n",
       "21    0.509074\n",
       "22    0.610411\n",
       "23    0.426553\n",
       "24    0.498326\n",
       "25    0.506523\n",
       "26    0.419296\n",
       "27    0.442421\n",
       "28    0.469671\n",
       "29    0.814016\n",
       "30    0.401138\n",
       "31    0.613689\n",
       "32    0.493714\n",
       "33    0.684257\n",
       "34    0.566229\n",
       "35    0.816302\n",
       "36    0.698844\n",
       "37    0.743879\n",
       "38    0.573736\n",
       "39    0.608932\n",
       "40    0.548680\n",
       "41    0.434427\n",
       "42    0.670619\n",
       "43    0.624228\n",
       "44    0.741159\n",
       "dtype: float64"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_users_scores[['LinearSVC','SVC']].max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_days = [ all_users_data[:15], all_users_data[15:30], all_users_data[30:]]\n",
    "\n",
    "df_all_results = pd.DataFrame()\n",
    "for data_day in data_days:\n",
    "    for user, user_data in enumerate(data_day):\n",
    "        score_summary = data_day[user].score_summary()\n",
    "        best_score = score_summary.loc[score_summary['mean_score'] == score_summary['mean_score'].max()]\n",
    "\n",
    "        df_all_results = df_results.append({'user': user+1, 'estimator': best_score.loc[0, 'estimator'], 'mean_score': best_score.loc[0, 'mean_score'] }, ignore_index=True)\n",
    "\n",
    "df_results.groupby(['user', 'estimator'])[['mean_score']].max()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 3: Subject dependent models with varying windows and overlaps\n",
    "#### - To limit execution time, only 3 users on the first day/session are used for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out of   5 | elapsed:   35.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   35.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0199s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0209s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[CV] ................ , score=(train=0.618, test=0.136), total=   0.1s\n",
      "[CV]  ................................................................\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] ................ , score=(train=0.549, test=0.416), total=   0.1s\n",
      "[CV]  ................................................................\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] ................ , score=(train=0.552, test=0.506), total=   0.1s\n",
      "[CV]  ................................................................\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] ................ , score=(train=0.532, test=0.565), total=   0.1s[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0210s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0229s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0219s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "\n",
      "Object persisted\n",
      "Running GridSearchCV for RandomForestClassifier with nested cross validation.\n",
      "[CV]  ................................................................\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1297s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    2.2s finished\n",
      "[CV] ................ , score=(train=1.000, test=0.367), total=   2.7s\n",
      "[CV]  ................................................................\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1326s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    2.1s finished\n",
      "[CV] ................ , score=(train=1.000, test=0.326), total=   3.0s\n",
      "[CV]  ................................................................\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    5.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1307s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    2.1s finished\n",
      "[CV] ................ , score=(train=1.000, test=0.266), total=   3.1s\n",
      "[CV]  ................................................................\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    8.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1316s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  20 | elapsed:    1.5s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    2.2s finished\n",
      "[CV] ................ , score=(train=1.000, test=0.219), total=   3.1s\n",
      "[CV]  ................................................................\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   12.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1277s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    2.0s finished\n",
      "[CV] ................ , score=(train=1.000, test=0.539), total=   2.5s\n",
      "Object persisted\n",
      "Running GridSearchCV for LogisticRegression with nested cross validation.\n",
      "[CV]  ................................................................\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   14.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   14.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0449s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1456s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  23 out of  30 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  30 | elapsed:    0.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0419s.) Setting batch_size=2.\n",
      "[CV] ................ , score=(train=0.557, test=0.399), total=   0.6s\n",
      "[CV]  ................................................................\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1486s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  23 out of  30 | elapsed:    0.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  30 | elapsed:    0.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    0.5s finished\n",
      "[CV] ................ , score=(train=0.640, test=0.057), total=   0.7s\n",
      "[CV]  ................................................................\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    1.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0409s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1237s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  23 out of  30 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  30 | elapsed:    0.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    1.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0399s.) Setting batch_size=2.\n",
      "[CV] ................ , score=(train=0.559, test=0.403), total=   0.6s\n",
      "[CV]  ................................................................\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1556s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  23 out of  30 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  30 | elapsed:    0.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    2.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[CV] ................ , score=(train=0.591, test=0.444), total=   0.6s\n",
      "[CV]  ................................................................\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0429s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1466s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  30 | elapsed:    0.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    3.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    3.0s finished\n",
      "[CV] ................ , score=(train=0.536, test=0.539), total=   0.6s\n",
      "Object persisted\n",
      "Running GridSearchCV for MLPClassifier with nested cross validation.\n",
      "[CV]  ................................................................\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    6.2s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    8.3s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   10.2s finished\n",
      "[CV] ................ , score=(train=0.817, test=0.296), total=  10.8s\n",
      "[CV]  ................................................................\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   10.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    6.6s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    8.3s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   10.4s finished\n",
      "[CV] ................ , score=(train=0.771, test=0.341), total=  11.1s\n",
      "[CV]  ................................................................\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   21.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    6.1s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    7.7s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    8.6s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    9.8s finished\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   32.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[CV] ................ , score=(train=0.760, test=0.247), total=  10.4s\n",
      "[CV]  ................................................................\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    5.1s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    6.9s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    8.9s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   10.0s finished\n",
      "[CV] ................ , score=(train=0.796, test=0.283), total=  10.7s\n",
      "[CV]  ................................................................\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   42.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    5.5s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    6.5s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    8.3s finished\n",
      "[CV] ................ , score=(train=0.666, test=0.445), total=   8.8s\n",
      "Object persisted\n",
      "Running GridSearchCV for LinearSVC with nested cross validation.\n",
      "[CV]  ................................................................\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   51.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   51.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    5.5s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    6.1s finished\n",
      "[CV] ................ , score=(train=0.556, test=0.408), total=   6.8s\n",
      "[CV]  ................................................................\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    6.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    6.1s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    6.8s finished\n",
      "[CV] ................ , score=(train=0.596, test=0.350), total=   7.5s\n",
      "[CV]  ................................................................\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   14.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    6.1s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    6.7s finished\n",
      "[CV] ................ , score=(train=0.615, test=0.145), total=   7.5s\n",
      "[CV]  ................................................................\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   21.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    5.1s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    6.3s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    6.9s finished\n",
      "[CV] ................ , score=(train=0.603, test=0.440), total=   7.7s\n",
      "[CV]  ................................................................\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   29.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    6.5s finished\n",
      "[CV] ................ , score=(train=0.545, test=0.570), total=   7.2s\n",
      "Object persisted\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   36.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   36.6s finished\n",
      "Wall time: 31min 22s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>estimator</th>\n",
       "      <th>min_score</th>\n",
       "      <th>max_score</th>\n",
       "      <th>mean_score</th>\n",
       "      <th>std_score</th>\n",
       "      <th>train_mean_score</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>estimator__C</th>\n",
       "      <th>estimator__alpha</th>\n",
       "      <th>estimator__hidden_layer_sizes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>0.319588</td>\n",
       "      <td>0.436508</td>\n",
       "      <td>0.384530</td>\n",
       "      <td>0.039319</td>\n",
       "      <td>0.513476</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.364261</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>0.419792</td>\n",
       "      <td>0.044398</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.316151</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.376207</td>\n",
       "      <td>0.039490</td>\n",
       "      <td>0.518120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.267943</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.359600</td>\n",
       "      <td>0.066116</td>\n",
       "      <td>0.691797</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(20, 15, 10)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.216495</td>\n",
       "      <td>0.448413</td>\n",
       "      <td>0.351649</td>\n",
       "      <td>0.087931</td>\n",
       "      <td>0.528748</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>0.135593</td>\n",
       "      <td>0.565141</td>\n",
       "      <td>0.403401</td>\n",
       "      <td>0.147465</td>\n",
       "      <td>0.561222</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.218884</td>\n",
       "      <td>0.538732</td>\n",
       "      <td>0.343459</td>\n",
       "      <td>0.109975</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.057203</td>\n",
       "      <td>0.538732</td>\n",
       "      <td>0.368412</td>\n",
       "      <td>0.163541</td>\n",
       "      <td>0.576678</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.246753</td>\n",
       "      <td>0.445423</td>\n",
       "      <td>0.322530</td>\n",
       "      <td>0.068454</td>\n",
       "      <td>0.762025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1e-07</td>\n",
       "      <td>(15, 10, 5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.145022</td>\n",
       "      <td>0.570423</td>\n",
       "      <td>0.382544</td>\n",
       "      <td>0.139090</td>\n",
       "      <td>0.582919</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows  11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    user                   estimator  min_score  max_score  mean_score  \\\n",
       "0      1  LinearDiscriminantAnalysis   0.319588   0.436508    0.384530   \n",
       "0      1      RandomForestClassifier   0.364261   0.472222    0.419792   \n",
       "0      1          LogisticRegression   0.316151   0.428571    0.376207   \n",
       "0      1               MLPClassifier   0.267943   0.444444    0.359600   \n",
       "0      1                   LinearSVC   0.216495   0.448413    0.351649   \n",
       "..   ...                         ...        ...        ...         ...   \n",
       "0      3  LinearDiscriminantAnalysis   0.135593   0.565141    0.403401   \n",
       "0      3      RandomForestClassifier   0.218884   0.538732    0.343459   \n",
       "0      3          LogisticRegression   0.057203   0.538732    0.368412   \n",
       "0      3               MLPClassifier   0.246753   0.445423    0.322530   \n",
       "0      3                   LinearSVC   0.145022   0.570423    0.382544   \n",
       "\n",
       "    std_score  train_mean_score n_estimators estimator__C estimator__alpha  \\\n",
       "0    0.039319          0.513476          NaN          NaN              NaN   \n",
       "0    0.044398          1.000000           16          NaN              NaN   \n",
       "0    0.039490          0.518120          NaN         0.01              NaN   \n",
       "0    0.066116          0.691797          NaN          NaN              0.1   \n",
       "0    0.087931          0.528748          NaN         32.0              NaN   \n",
       "..        ...               ...          ...          ...              ...   \n",
       "0    0.147465          0.561222          NaN          NaN              NaN   \n",
       "0    0.109975          1.000000           16          NaN              NaN   \n",
       "0    0.163541          0.576678          NaN         0.01              NaN   \n",
       "0    0.068454          0.762025          NaN          NaN            1e-07   \n",
       "0    0.139090          0.582919          NaN         32.0              NaN   \n",
       "\n",
       "   estimator__hidden_layer_sizes  \n",
       "0                            NaN  \n",
       "0                            NaN  \n",
       "0                            NaN  \n",
       "0                   (20, 15, 10)  \n",
       "0                            NaN  \n",
       "..                           ...  \n",
       "0                            NaN  \n",
       "0                            NaN  \n",
       "0                            NaN  \n",
       "0                    (15, 10, 5)  \n",
       "0                            NaN  \n",
       "\n",
       "[90 rows x 11 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "%load_ext autoreload\n",
    "%autoreload \n",
    "from helpers import StratifiedGroupKFold\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, Normalizer, PowerTransformer, MinMaxScaler\n",
    "from sklearn.feature_selection import f_classif, SelectKBest, chi2, mutual_info_classif\n",
    "from sklearn.decomposition import PCA\n",
    "from helpers import EstimatorSelectionHelper\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis \n",
    "from datetime import datetime\n",
    "import pickle\n",
    "from sklearn.model_selection import GroupKFold, StratifiedShuffleSplit, StratifiedKFold\n",
    "\n",
    "cols = ['session', 'trial', 'user', 'label', 'T7', 'T8', 'FT7', 'FT8', 'TP7', 'TP8']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_user_scores = pd.DataFrame()\n",
    "\n",
    "\n",
    "\n",
    "folder = './models/user-dependent-varying-window-and-overlap'\n",
    "win_overlaps = [(800, 400), (800, 0), (400, 200), (400, 0), (200, 100), (200, 0)]\n",
    "# win_overlaps = [(400, 200), (400, 0), (200, 100), (200, 0)]\n",
    "\n",
    "\n",
    "for window_size, overlap_size in win_overlaps:\n",
    "    user_helper_list = []\n",
    "\n",
    "    df_features = read_features_file('D:\\\\facul\\\\features', window_size, overlap_size)\n",
    "    # Use only first day/session\n",
    "    df_features_cols = df_features.loc[df_features['session'] == 1, df_features.filter(regex=r\"({})\".format('|'.join(cols)), axis=1).columns]\n",
    "\n",
    "    # Only first 3 users\n",
    "    for user in range(1, 4):\n",
    "\n",
    "        # cv_grp = RepeatedStratifiedGroupKFold(n_splits=5, n_repeats=1)\n",
    "        # outer_cv_grp = RepeatedStratifiedGroupKFold(n_splits=5, n_repeats=1)\n",
    "        cv_grp = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "        outer_cv_grp = StratifiedGroupKFold(n_splits=5)   \n",
    "\n",
    "\n",
    "        print(outer_cv_grp.get_n_splits())\n",
    "\n",
    "        helper = EstimatorSelectionHelper(models, params)\n",
    "        user_helper_list.append(helper)\n",
    "\n",
    "        user_day_index = df_features_cols['user'].isin([user])\n",
    "\n",
    "        X = df_features_cols.loc[user_day_index, ~df_features_cols.columns.isin(['session', 'trial', 'user', 'label'])]\n",
    "        y = df_features_cols.loc[user_day_index, 'label'].astype(int)\n",
    "\n",
    "        groups = df_features_cols.loc[user_day_index, 'trial']\n",
    "\n",
    "        # helper.fit(X, y, scoring='f1', n_jobs=2, cv=cv_grp, outer_cv=outer_cv_grp, groups=df_features_cols['trial'])\n",
    "        helper.fit(X, y, scoring='accuracy', n_jobs=-1, cv=cv_grp, outer_cv=outer_cv_grp, verbose=10, groups=groups, persist_dir=f\"{folder}/user_{user}_win_{window_size}_overlap_{overlap_size}_{datetime.now().strftime('%Y-%m-%dT%H-%M-%S.pkl')}\", randomSearchFor=['MLPClassifier', 'SVC'])\n",
    "\n",
    "        temp_scores = helper.score_summary(sort_by='mean_score')\n",
    "        temp_scores.insert(0, 'user', user)\n",
    "        df_user_scores = df_user_scores.append(temp_scores)\n",
    "\n",
    "    with open(f\"{folder}/all_users_win_{window_size}_overlap_{overlap_size}_{datetime.now().strftime('%Y-%m-%dT%H-%M-%S.pkl')}\", \"wb\") as f:\n",
    "        pickle.dump(user_helper_list, f)\n",
    "\n",
    "df_user_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>window</th>\n",
       "      <th>overlap</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">200</th>\n",
       "      <th>0</th>\n",
       "      <td>0.466692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.472884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">400</th>\n",
       "      <th>0</th>\n",
       "      <td>0.476674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0.475305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">800</th>\n",
       "      <th>0</th>\n",
       "      <td>0.451227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>0.479198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                mean_score\n",
       "window overlap            \n",
       "200    0          0.466692\n",
       "       100        0.472884\n",
       "400    0          0.476674\n",
       "       200        0.475305\n",
       "800    0          0.451227\n",
       "       400        0.479198"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_dir = './models/user-dependent-varying-window-and-overlap'\n",
    "\n",
    "windows_configs = {\n",
    "    'win_200_overlap_0': EstimatorSelectionHelper.load(f\"{files_dir}/all_users_win_200_overlap_0_2020-06-21T00-15-44.pkl\"),\n",
    "    'win_200_overlap_100': EstimatorSelectionHelper.load(f\"{files_dir}/all_users_win_200_overlap_100_2020-06-21T00-10-13.pkl\"),\n",
    "    'win_400_overlap_0': EstimatorSelectionHelper.load(f\"{files_dir}/all_users_win_400_overlap_0_2020-06-20T23-57-51.pkl\"),\n",
    "    'win_400_overlap_200': EstimatorSelectionHelper.load(f\"{files_dir}/all_users_win_400_overlap_200_2020-06-20T23-54-51.pkl\"),\n",
    "    'win_800_overlap_0': EstimatorSelectionHelper.load(f\"{files_dir}/all_users_win_800_overlap_0_2020-06-20T23-49-31.pkl\"),\n",
    "    'win_800_overlap_400': EstimatorSelectionHelper.load(f\"{files_dir}/all_users_win_800_overlap_400_2020-06-20T23-47-36.pkl\"),\n",
    "}\n",
    "\n",
    "df_user_scores = pd.DataFrame()\n",
    "for conf in windows_configs:\n",
    "    win_size, overlap_size = conf.split('_')[1], conf.split('_')[3]\n",
    "    df_window_scores = df_window_scores.append({'window': win_size, 'overlap': overlap_size}, ignore_index=True)\n",
    "\n",
    "    for user_results in windows_configs[conf]:\n",
    "\n",
    "        temp_scores = user_results.score_summary(sort_by='mean_score')\n",
    "        temp_scores.insert(0, 'window', win_size)\n",
    "        temp_scores.insert(1, 'overlap', overlap_size)\n",
    "\n",
    "        df_user_scores = df_user_scores.append(temp_scores)\n",
    "\n",
    "\n",
    "    # df_window_scores[conf].score_summary().groupby\n",
    "df_user_scores.groupby(['window', 'overlap']).agg({'mean_score': 'mean'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 4: Subject-independent models with sessions within the same days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f  50 | elapsed:  4.7min finished\n",
      "[CV] ................ , score=(train=0.482, test=0.422), total= 4.9min\n",
      "[CV]  ................................................................\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  5.0min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  6.1min\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  7.3min\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  7.9min\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  9.3min\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 10.2min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed: 10.9min finished\n",
      "[CV] ................ , score=(train=0.446, test=0.367), total=11.6min\n",
      "[CV]  ................................................................\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed: 16.8min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:   43.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  5.7min finished\n",
      "[CV] ................ , score=(train=0.635, test=0.504), total= 6.0min\n",
      "[CV]  ................................................................\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed: 23.0min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  7.5min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  9.5min finished\n",
      "[CV] ................ , score=(train=0.983, test=0.463), total=11.4min\n",
      "[CV]  ................................................................\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed: 34.4min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  5.4min\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  7.0min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  9.1min finished\n",
      "[CV] ................ , score=(train=0.418, test=0.497), total= 9.3min\n",
      "Object persisted\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 43.9min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 43.9min finished\n",
      "dict_keys(['LogisticRegression', 'MLPClassifier', 'LinearSVC', 'SVC'])\n",
      "Running GridSearchCV for LogisticRegression with nested cross validation.\n",
      "[CV]  ................................................................\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  30 | elapsed:    3.9s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    4.1s finished\n",
      "[CV] ................ , score=(train=0.385, test=0.326), total=   4.5s\n",
      "[CV]  ................................................................\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  30 | elapsed:    3.4s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    4.0s finished\n",
      "[CV] ................ , score=(train=0.384, test=0.343), total=   4.8s\n",
      "[CV]  ................................................................\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    9.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  30 | elapsed:    4.3s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    4.7s finished\n",
      "[CV] ................ , score=(train=0.373, test=0.363), total=   5.3s\n",
      "[CV]  ................................................................\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   14.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  30 | elapsed:    4.5s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    4.8s finished\n",
      "[CV] ................ , score=(train=0.359, test=0.476), total=   5.5s\n",
      "[CV]  ................................................................\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   20.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  30 | elapsed:    4.4s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    5.0s finished\n",
      "[CV] ................ , score=(train=0.485, test=0.429), total=   5.7s\n",
      "Object persisted\n",
      "Running GridSearchCV for MLPClassifier with nested cross validation.\n",
      "[CV]  ................................................................\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   25.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   25.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:   10.7s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   15.9s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   21.8s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   30.0s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   42.6s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   50.5s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  1.0min finished\n",
      "[CV] ................ , score=(train=0.387, test=0.341), total= 1.2min\n",
      "[CV]  ................................................................\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.2min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    5.7s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   13.4s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   19.5s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   30.3s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   35.3s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   47.2s finished\n",
      "[CV] ................ , score=(train=0.385, test=0.344), total=  50.8s\n",
      "[CV]  ................................................................\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  2.0min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    8.3s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   14.3s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   19.5s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   28.5s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   38.8s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   43.4s finished\n",
      "[CV] ................ , score=(train=0.372, test=0.363), total=  43.8s\n",
      "[CV]  ................................................................\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  2.7min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   10.6s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   14.1s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   23.8s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   31.6s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   37.6s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   45.4s finished\n",
      "[CV] ................ , score=(train=0.435, test=0.463), total=  47.9s\n",
      "[CV]  ................................................................\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  3.5min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:   11.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   15.3s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   18.5s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   30.5s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   40.5s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  1.3min finished\n",
      "[CV] ................ , score=(train=0.660, test=0.487), total= 1.4min\n",
      "Object persisted\n",
      "Running GridSearchCV for LinearSVC with nested cross validation.\n",
      "[CV]  ................................................................\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  4.9min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  4.9min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:   21.8s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   35.3s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   52.1s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  1.8min finished\n",
      "[CV] ................ , score=(train=0.387, test=0.336), total= 1.9min\n",
      "[CV]  ................................................................\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.9min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:   21.0s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   33.9s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   48.5s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  1.6min finished\n",
      "[CV] ................ , score=(train=0.395, test=0.363), total= 1.7min\n",
      "[CV]  ................................................................\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  3.6min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:   25.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   40.6s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  2.0min finished\n",
      "[CV] ................ , score=(train=0.373, test=0.363), total= 2.1min\n",
      "[CV]  ................................................................\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  5.7min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:   25.6s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   39.2s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   58.3s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  2.0min finished\n",
      "[CV] ................ , score=(train=0.395, test=0.509), total= 2.1min\n",
      "[CV]  ................................................................\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  7.8min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:   22.5s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   37.4s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  2.7min finished\n",
      "[CV] ................ , score=(train=0.500, test=0.437), total= 2.9min\n",
      "Object persisted\n",
      "Running GridSearchCV for SVC with nested cross validation.\n",
      "[CV]  ................................................................\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 10.7min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 10.7min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:   47.6s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  5.4min finished\n",
      "[CV] ................ , score=(train=0.588, test=0.511), total= 5.8min\n",
      "[CV]  ................................................................\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  5.9min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:   45.3s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  7.8min finished\n",
      "[CV] ................ , score=(train=0.890, test=0.572), total=10.8min\n",
      "[CV]  ................................................................\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed: 16.8min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:   46.0s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  5.9min finished\n",
      "[CV] ................ , score=(train=0.396, test=0.372), total= 6.3min\n",
      "[CV]  ................................................................\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed: 23.2min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:   48.5s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  6.9min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  7.8min finished\n",
      "[CV] ................ , score=(train=0.885, test=0.645), total=11.0min\n",
      "[CV]  ................................................................\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed: 34.4min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:   52.4s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  6.7min finished\n",
      "[CV] ................ , score=(train=0.723, test=0.511), total= 7.6min\n",
      "Object persisted\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 42.2min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 42.2min finished\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df_user_scores' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_user_scores' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%load_ext autoreload\n",
    "%autoreload \n",
    "from helpers import RepeatedStratifiedGroupKFold\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, Normalizer, PowerTransformer, MinMaxScaler\n",
    "from sklearn.feature_selection import f_classif, SelectKBest, chi2, mutual_info_classif\n",
    "from sklearn.decomposition import PCA\n",
    "from helpers import EstimatorSelectionHelper\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis \n",
    "from datetime import datetime\n",
    "import pickle\n",
    "\n",
    "cols = ['session', 'trial', 'user', 'label', 'T7', 'T8', 'FT7', 'FT8', 'TP7', 'TP8']\n",
    "\n",
    "df_features = read_features_file('D:\\\\facul\\\\features', 800, 400)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_scores = pd.DataFrame()\n",
    "helper_list = []\n",
    "folder = './models/user-independent-same-days'\n",
    "\n",
    "for day in range(1, 4):\n",
    "    df_features_cols = df_features.loc[df_features['session'] == day, df_features.filter(regex=r\"({})\".format('|'.join(cols)), axis=1).columns]\n",
    "    cv_grp = RepeatedStratifiedGroupKFold(n_splits=5, n_repeats=1)\n",
    "    outer_cv_grp = RepeatedStratifiedGroupKFold(n_splits=5, n_repeats=1)\n",
    "\n",
    "    helper = EstimatorSelectionHelper(models, params)\n",
    "    helper_list.append(helper)\n",
    "\n",
    "\n",
    "    X = df_features_cols.loc[:, ~df_features_cols.columns.isin(['session', 'trial', 'user', 'label'])]\n",
    "    \n",
    "    y = df_features_cols.loc[:, 'label'].astype(int)\n",
    "\n",
    "    groups = df_features_cols.loc[:, 'trial']\n",
    "\n",
    "    # helper.fit(X, y, scoring='f1', n_jobs=2, cv=cv_grp, outer_cv=outer_cv_grp, groups=df_features_cols['trial'])\n",
    "    helper.fit(X, y, scoring='accuracy', n_jobs=-1, cv=cv_grp, outer_cv=outer_cv_grp, verbose=10, groups=groups, persist_dir=f\"{folder}/day_{day}_{datetime.now().strftime('%Y-%m-%dT%H-%M-%S.pkl')}\", randomSearchFor=['MLPClassifier', 'SVC'])\n",
    "\n",
    "    temp_scores = helper.score_summary(sort_by='mean_score')\n",
    "    temp_scores.insert(0, 'day', day)\n",
    "    df_scores = df_scores.append(temp_scores)\n",
    "\n",
    "with open(f\"{folder}/all_days_{datetime.now().strftime('%Y-%m-%dT%H-%M-%S.pkl')}\", \"wb\") as f:\n",
    "    pickle.dump(helper_list, f)\n",
    "\n",
    "df_user_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>estimator</th>\n",
       "      <th>min_score</th>\n",
       "      <th>max_score</th>\n",
       "      <th>mean_score</th>\n",
       "      <th>std_score</th>\n",
       "      <th>train_mean_score</th>\n",
       "      <th>estimator__C</th>\n",
       "      <th>estimator__hidden_layer_sizes</th>\n",
       "      <th>estimator__alpha</th>\n",
       "      <th>estimator__gamma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.367927</td>\n",
       "      <td>0.483749</td>\n",
       "      <td>0.403516</td>\n",
       "      <td>0.042812</td>\n",
       "      <td>0.414465</td>\n",
       "      <td>0.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.362074</td>\n",
       "      <td>0.461210</td>\n",
       "      <td>0.404945</td>\n",
       "      <td>0.037572</td>\n",
       "      <td>0.429209</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(15, 10)</td>\n",
       "      <td>0.001</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.370074</td>\n",
       "      <td>0.476868</td>\n",
       "      <td>0.423402</td>\n",
       "      <td>0.042487</td>\n",
       "      <td>0.443583</td>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.442153</td>\n",
       "      <td>0.525678</td>\n",
       "      <td>0.472046</td>\n",
       "      <td>0.029666</td>\n",
       "      <td>0.537359</td>\n",
       "      <td>0.0001220703125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.514603</td>\n",
       "      <td>0.434235</td>\n",
       "      <td>0.050916</td>\n",
       "      <td>0.467147</td>\n",
       "      <td>0.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.434830</td>\n",
       "      <td>0.550554</td>\n",
       "      <td>0.493385</td>\n",
       "      <td>0.037853</td>\n",
       "      <td>0.595323</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(20, 15, 10)</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.380408</td>\n",
       "      <td>0.498730</td>\n",
       "      <td>0.446042</td>\n",
       "      <td>0.040429</td>\n",
       "      <td>0.482866</td>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.367347</td>\n",
       "      <td>0.503526</td>\n",
       "      <td>0.450435</td>\n",
       "      <td>0.050632</td>\n",
       "      <td>0.592567</td>\n",
       "      <td>6.103515625e-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.325552</td>\n",
       "      <td>0.476136</td>\n",
       "      <td>0.387260</td>\n",
       "      <td>0.056558</td>\n",
       "      <td>0.397168</td>\n",
       "      <td>0.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.340904</td>\n",
       "      <td>0.487419</td>\n",
       "      <td>0.399655</td>\n",
       "      <td>0.062583</td>\n",
       "      <td>0.447798</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(30, 15, 10)</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.335857</td>\n",
       "      <td>0.509091</td>\n",
       "      <td>0.401583</td>\n",
       "      <td>0.063445</td>\n",
       "      <td>0.409943</td>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.371806</td>\n",
       "      <td>0.644657</td>\n",
       "      <td>0.522068</td>\n",
       "      <td>0.089821</td>\n",
       "      <td>0.696311</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   day           estimator  min_score  max_score  mean_score  std_score  \\\n",
       "0    1  LogisticRegression   0.367927   0.483749    0.403516   0.042812   \n",
       "0    1       MLPClassifier   0.362074   0.461210    0.404945   0.037572   \n",
       "0    1           LinearSVC   0.370074   0.476868    0.423402   0.042487   \n",
       "0    1                 SVC   0.442153   0.525678    0.472046   0.029666   \n",
       "0    2  LogisticRegression   0.380952   0.514603    0.434235   0.050916   \n",
       "0    2       MLPClassifier   0.434830   0.550554    0.493385   0.037853   \n",
       "0    2           LinearSVC   0.380408   0.498730    0.446042   0.040429   \n",
       "0    2                 SVC   0.367347   0.503526    0.450435   0.050632   \n",
       "0    3  LogisticRegression   0.325552   0.476136    0.387260   0.056558   \n",
       "0    3       MLPClassifier   0.340904   0.487419    0.399655   0.062583   \n",
       "0    3           LinearSVC   0.335857   0.509091    0.401583   0.063445   \n",
       "0    3                 SVC   0.371806   0.644657    0.522068   0.089821   \n",
       "\n",
       "   train_mean_score     estimator__C estimator__hidden_layer_sizes  \\\n",
       "0          0.414465             0.01                           NaN   \n",
       "0          0.429209              NaN                      (15, 10)   \n",
       "0          0.443583             32.0                           NaN   \n",
       "0          0.537359  0.0001220703125                           NaN   \n",
       "0          0.467147             0.01                           NaN   \n",
       "0          0.595323              NaN                  (20, 15, 10)   \n",
       "0          0.482866             32.0                           NaN   \n",
       "0          0.592567  6.103515625e-05                           NaN   \n",
       "0          0.397168             0.01                           NaN   \n",
       "0          0.447798              NaN                  (30, 15, 10)   \n",
       "0          0.409943             32.0                           NaN   \n",
       "0          0.696311              1.0                           NaN   \n",
       "\n",
       "  estimator__alpha estimator__gamma  \n",
       "0              NaN              NaN  \n",
       "0            0.001              NaN  \n",
       "0              NaN              NaN  \n",
       "0              NaN              0.1  \n",
       "0              NaN              NaN  \n",
       "0            1e-05              NaN  \n",
       "0              NaN              NaN  \n",
       "0              NaN       10000000.0  \n",
       "0              NaN              NaN  \n",
       "0              0.1              NaN  \n",
       "0              NaN              NaN  \n",
       "0              NaN              1.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "window              5.338672e+43\n",
       "overlap             2.669336e+43\n",
       "min_score           3.365907e-01\n",
       "max_score           5.947198e-01\n",
       "mean_score          4.791984e-01\n",
       "std_score           9.289172e-02\n",
       "train_mean_score    7.498655e-01\n",
       "dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_user_scores[(df_user_scores['window'] == '800') & (df_user_scores['overlap'] == '400')].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'score_summary'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-1009aa821492>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mwindows_configs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'win_800_overlap_0'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore_summary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'score_summary'"
     ]
    }
   ],
   "source": [
    "windows_configs['win_800_overlap_0'].score_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    820\n",
      "0    697\n",
      "2    437\n",
      "Name: label, dtype: int64\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No active exception to reraise",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-305ffbba1e67>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0my2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_features_cols2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'label'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mtrain_idx2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_idx2\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcv_grp2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;31m# for train_idx, test_idx in stratified_group_k_fold(train_x, y=train_y, groups=train_groups, k=4, seed=0):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: No active exception to reraise"
     ]
    }
   ],
   "source": [
    "cv_grp = RepeatedStratifiedGroupKFold(n_splits=5, n_repeats=1)\n",
    "cv_grp2 = RepeatedStratifiedGroupKFold(n_splits=5, n_repeats=1)\n",
    "\n",
    "df_features = read_features_file('D:\\\\facul\\\\features', 400, 200)\n",
    "df_features_cols = df_features.loc[df_features['session'] == 1, df_features.filter(regex=r\"({})\".format('|'.join(cols)), axis=1).columns]\n",
    "X = df_features_cols.loc[df_features_cols['user'].isin([1]), ~df_features_cols.columns.isin(['session', 'trial', 'user', 'label'])]\n",
    "\n",
    "X.shape\n",
    "y = df_features_cols.loc[df_features_cols['user'].isin([1]), 'label'].astype(int)\n",
    "\n",
    "groups = df_features_cols.loc[df_features_cols['user'].isin([1]), 'trial']\n",
    "for train_idx, test_idx in cv_grp.split(X, y=y, groups=groups):\n",
    "    df_features_cols2 = df_features_cols[df_features_cols.index.isin(train_idx)]\n",
    "    X2 = df_features_cols2.loc[:, ~df_features_cols2.columns.isin(['session', 'trial', 'user', 'label'])]\n",
    "    y2 = df_features_cols2.loc[:, 'label'].astype(int)\n",
    "    print(y2.value_counts())\n",
    "    raise\n",
    "    for train_idx2, test_idx2 in cv_grp2.split(X2, y=y2, groups=groups):\n",
    "    # for train_idx, test_idx in stratified_group_k_fold(train_x, y=train_y, groups=train_groups, k=4, seed=0):\n",
    "        print(\"TRAIN:\")\n",
    "        print(df_features_cols2[df_features_cols2.index.isin(train_idx2)]['label'].value_counts(normalize=True))\n",
    "        print(\"TEST:\")\n",
    "        print(df_features_cols2[df_features_cols2.index.isin(test_idx2)]['label'].value_counts(normalize=True))\n",
    "\n",
    "        print(\"-----------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>user</th>\n",
       "      <th>estimator</th>\n",
       "      <th>min_score</th>\n",
       "      <th>max_score</th>\n",
       "      <th>mean_score</th>\n",
       "      <th>std_score</th>\n",
       "      <th>train_mean_score</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>estimator__C</th>\n",
       "      <th>estimator__alpha</th>\n",
       "      <th>estimator__hidden_layer_sizes</th>\n",
       "      <th>estimator__gamma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>0.277512</td>\n",
       "      <td>0.511111</td>\n",
       "      <td>0.382965</td>\n",
       "      <td>0.083175</td>\n",
       "      <td>0.512056</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.367698</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>0.413429</td>\n",
       "      <td>0.043020</td>\n",
       "      <td>0.998772</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.420635</td>\n",
       "      <td>0.366543</td>\n",
       "      <td>0.036591</td>\n",
       "      <td>0.470970</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.311005</td>\n",
       "      <td>0.460317</td>\n",
       "      <td>0.378056</td>\n",
       "      <td>0.057923</td>\n",
       "      <td>0.660978</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001</td>\n",
       "      <td>(10, 5)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.287081</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.389457</td>\n",
       "      <td>0.053441</td>\n",
       "      <td>0.494454</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.698864</td>\n",
       "      <td>0.838346</td>\n",
       "      <td>0.798162</td>\n",
       "      <td>0.050510</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.590308</td>\n",
       "      <td>0.924812</td>\n",
       "      <td>0.744512</td>\n",
       "      <td>0.131901</td>\n",
       "      <td>0.898900</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.555024</td>\n",
       "      <td>0.890977</td>\n",
       "      <td>0.731323</td>\n",
       "      <td>0.113036</td>\n",
       "      <td>0.995100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(20, 15, 10)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.555024</td>\n",
       "      <td>0.909774</td>\n",
       "      <td>0.741159</td>\n",
       "      <td>0.135552</td>\n",
       "      <td>0.892107</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.573864</td>\n",
       "      <td>0.810726</td>\n",
       "      <td>0.710464</td>\n",
       "      <td>0.082012</td>\n",
       "      <td>0.906919</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1e-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>270 rows  13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    day  user                   estimator  min_score  max_score  mean_score  \\\n",
       "0     1     1  LinearDiscriminantAnalysis   0.277512   0.511111    0.382965   \n",
       "0     1     1      RandomForestClassifier   0.367698   0.472222    0.413429   \n",
       "0     1     1          LogisticRegression   0.315789   0.420635    0.366543   \n",
       "0     1     1               MLPClassifier   0.311005   0.460317    0.378056   \n",
       "0     1     1                   LinearSVC   0.287081   0.444444    0.389457   \n",
       "..  ...   ...                         ...        ...        ...         ...   \n",
       "0     3    15      RandomForestClassifier   0.698864   0.838346    0.798162   \n",
       "0     3    15          LogisticRegression   0.590308   0.924812    0.744512   \n",
       "0     3    15               MLPClassifier   0.555024   0.890977    0.731323   \n",
       "0     3    15                   LinearSVC   0.555024   0.909774    0.741159   \n",
       "0     3    15                         SVC   0.573864   0.810726    0.710464   \n",
       "\n",
       "    std_score  train_mean_score n_estimators estimator__C estimator__alpha  \\\n",
       "0    0.083175          0.512056          NaN          NaN              NaN   \n",
       "0    0.043020          0.998772           16          NaN              NaN   \n",
       "0    0.036591          0.470970          NaN         0.01              NaN   \n",
       "0    0.057923          0.660978          NaN          NaN            0.001   \n",
       "0    0.053441          0.494454          NaN         32.0              NaN   \n",
       "..        ...               ...          ...          ...              ...   \n",
       "0    0.050510          1.000000           16          NaN              NaN   \n",
       "0    0.131901          0.898900          NaN         0.01              NaN   \n",
       "0    0.113036          0.995100          NaN          NaN              0.1   \n",
       "0    0.135552          0.892107          NaN         32.0              NaN   \n",
       "0    0.082012          0.906919          NaN         0.25              NaN   \n",
       "\n",
       "   estimator__hidden_layer_sizes estimator__gamma  \n",
       "0                            NaN              NaN  \n",
       "0                            NaN              NaN  \n",
       "0                            NaN              NaN  \n",
       "0                        (10, 5)              NaN  \n",
       "0                            NaN              NaN  \n",
       "..                           ...              ...  \n",
       "0                            NaN              NaN  \n",
       "0                            NaN              NaN  \n",
       "0                   (20, 15, 10)              NaN  \n",
       "0                            NaN              NaN  \n",
       "0                            NaN            1e-05  \n",
       "\n",
       "[270 rows x 13 columns]"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_user_scores[df_user_scores['user'] == 6]\n",
    "df_user_scores.groupby('user')['mean_score'].max().mean()\n",
    "df_user_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['FP1_de_theta', 'FP1_de_gamma', 'FP2_de_theta', 'FP2_de_alpha',\n",
       "       'FP2_de_gamma', 'AF4_de_theta', 'F7_de_beta', 'F7_de_gamma',\n",
       "       'F4_de_gamma', 'F6_de_gamma', 'F8_de_gamma', 'FT7_de_gamma',\n",
       "       'FC5_de_beta', 'FC5_de_gamma', 'FC4_de_gamma', 'FC6_de_beta',\n",
       "       'FC6_de_gamma', 'FT8_de_gamma', 'T7_de_delta', 'T7_de_beta',\n",
       "       'T7_de_gamma', 'C5_de_gamma', 'C3_de_gamma', 'C2_de_gamma',\n",
       "       'C4_de_beta', 'C4_de_gamma', 'C6_de_beta', 'C6_de_gamma',\n",
       "       'T8_de_gamma', 'TP7_de_beta', 'TP7_de_gamma', 'CP5_de_beta',\n",
       "       'CP5_de_gamma', 'CP3_de_gamma', 'CP1_de_gamma', 'CP4_de_beta',\n",
       "       'CP4_de_gamma', 'TP8_de_gamma', 'P7_de_beta', 'P7_de_gamma',\n",
       "       'P5_de_gamma', 'P3_de_gamma', 'PZ_de_gamma', 'PO7_de_gamma',\n",
       "       'PO5_de_gamma', 'PO3_de_gamma', 'PO4_de_gamma', 'CB1_de_gamma',\n",
       "       'O1_de_beta', 'O1_de_gamma'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features.columns.values[4:][helper1.grid_searches['SVC'].best_estimator_.named_steps['feat'].get_support()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save models to Production"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load all model's for an experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = EstimatorSelectionHelper.load('./models/user-dependent-same-days/all_users_day_2_2020-06-20T17-49-08.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get model with highest score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimator</th>\n",
       "      <th>min_score</th>\n",
       "      <th>max_score</th>\n",
       "      <th>mean_score</th>\n",
       "      <th>std_score</th>\n",
       "      <th>train_mean_score</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>estimator__C</th>\n",
       "      <th>estimator__alpha</th>\n",
       "      <th>estimator__hidden_layer_sizes</th>\n",
       "      <th>estimator__gamma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.460481</td>\n",
       "      <td>0.853333</td>\n",
       "      <td>0.730137</td>\n",
       "      <td>0.138959</td>\n",
       "      <td>0.883166</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   estimator  min_score  max_score  mean_score  std_score  train_mean_score  \\\n",
       "0  LinearSVC   0.460481   0.853333    0.730137   0.138959          0.883166   \n",
       "\n",
       "  n_estimators estimator__C estimator__alpha estimator__hidden_layer_sizes  \\\n",
       "0          NaN         32.0              NaN                           NaN   \n",
       "\n",
       "  estimator__gamma  \n",
       "0              NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = temp[14].score_summary()\n",
    "df\n",
    "df[df['mean_score'] == df['mean_score'].max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=<helpers.RepeatedStratifiedGroupKFold object at 0x00000240F82B80B8>,\n",
       "             error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('scaling',\n",
       "                                        StandardScaler(copy=True,\n",
       "                                                       with_mean=True,\n",
       "                                                       with_std=True)),\n",
       "                                       ('estimator',\n",
       "                                        LinearSVC(C=1.0, class_weight=None,\n",
       "                                                  dual=True, fit_intercept=True,\n",
       "                                                  intercept_scaling=1,\n",
       "                                                  loss='squared_hinge',\n",
       "                                                  max_iter=1000,\n",
       "                                                  multi_class='ovr'...\n",
       "                                                  random_state=None, tol=0.0001,\n",
       "                                                  verbose=0))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid=[{'estimator__C': array([3.20000000e+01, 1.48139954e+01, 6.85795186e+00, 3.17480210e+00,\n",
       "       1.46973449e+00, 6.80395000e-01, 3.14980262e-01, 1.45816130e-01,\n",
       "       6.75037337e-02, 3.12500000e-02])}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='accuracy', verbose=10)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp[14].grid_searches['LinearSVC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if model is fitted\n",
    "# from https://stackoverflow.com/a/48046685\n",
    "\n",
    "import inspect\n",
    "\n",
    "def is_fitted(model):\n",
    "        \"\"\"Checks if model object has any attributes ending with an underscore\"\"\"\n",
    "        return 0 < len( [k for k,v in inspect.getmembers(model) if k.endswith('_') and not k.startswith('__')] )\n",
    "\n",
    "is_fitted(temp[3].grid_searches['LinearSVC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (1,25) (30,) (1,25) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-4d7df5a93369>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0many_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtemp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrid_searches\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'LinearSVC'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0many_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\programs\\anaconda\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[1;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m         \u001b[1;31m# update the docstring of the returned function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\programs\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    475\u001b[0m         \"\"\"\n\u001b[0;32m    476\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'predict'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 477\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    478\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mif_delegate_has_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'best_estimator_'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'estimator'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\programs\\anaconda\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[1;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m         \u001b[1;31m# update the docstring of the returned function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\programs\\anaconda\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X, **predict_params)\u001b[0m\n\u001b[0;32m    417\u001b[0m         \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    418\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwith_final\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 419\u001b[1;33m             \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    420\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpredict_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\programs\\anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X, copy)\u001b[0m\n\u001b[0;32m    804\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    805\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_mean\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 806\u001b[1;33m                 \u001b[0mX\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    807\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_std\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    808\u001b[0m                 \u001b[0mX\u001b[0m \u001b[1;33m/=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscale_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (1,25) (30,) (1,25) "
     ]
    }
   ],
   "source": [
    "any_features = np.random.rand(5,5).reshape(1, -1)\n",
    "temp[3].grid_searches['LinearSVC'].predict(any_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model for production usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../openbci/best_model_with_scaling.sav']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(temp[14].grid_searches['LinearSVC'], '../../openbci/best_model_with_scaling.sav')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
